"""A4å®éªŒç»„åˆ†æï¼šå¥–åŠ±å‡½æ•°å¯¹æ¯”

åˆ†æä¸åŒå¥–åŠ±å‡½æ•°è®¾è®¡å¯¹è®­ç»ƒæ•ˆæœçš„å½±å“
"""

import os
import sys
import numpy as np
import pandas as pd
from pathlib import Path
import matplotlib.pyplot as plt

sys.path.insert(0, str(Path(__file__).parent.parent))

from analysis.data_loader import scan_experiment_results, group_experiments_by
from analysis.metrics_calculator import calculate_all_metrics, extract_eval_metrics
from analysis.visualization import (
    plot_learning_curves,
    configure_plot_style,
)


def parse_reward_name(exp_name: str) -> str:
    """ä»å®éªŒåç§°ä¸­æå–å¥–åŠ±å‡½æ•°ç±»å‹ï¼ˆç§»é™¤æ—¶é—´æˆ³ï¼‰"""
    # ä»exp_nameä¸­æå–rewardç±»å‹
    # ä¾‹å¦‚ï¼šsac_exp_a4_reward_baseline_20260108_124435 -> Baseline
    
    parts = exp_name.split('_')
    for i, part in enumerate(parts):
        if part == 'reward' and i+1 < len(parts):
            reward_type = parts[i+1]
            # è½¬æ¢ä¸ºé¦–å­—æ¯å¤§å†™
            if reward_type == 'baseline':
                return 'Baseline'
            elif reward_type == 'sparse':
                return 'Sparse'
            elif reward_type == 'dense':
                return 'Dense'
            elif reward_type == 'nostep':
                return 'NoStep'
            elif reward_type == 'energy':
                return 'Energy'
    return 'Unknown'


def main():
    """ä¸»å‡½æ•°ï¼šA4å¥–åŠ±å‡½æ•°å¯¹æ¯”åˆ†æ"""
    
    print("="*80)
    print("A4 å®éªŒç»„åˆ†æï¼šå¥–åŠ±å‡½æ•°å¯¹æ¯”")
    print("="*80)
    
    # é…ç½®è·¯å¾„
    results_dir = Path(__file__).parent.parent / 'results'
    a4_dir = results_dir / 'a4'
    output_dir = a4_dir / 'analysis'
    figures_dir = output_dir / 'figures'
    
    output_dir.mkdir(parents=True, exist_ok=True)
    figures_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"\nğŸ“‚ åŠ è½½å®éªŒæ•°æ®...")
    experiments = scan_experiment_results(str(results_dir), experiment_group='a4')
    
    if not experiments:
        print("âŒ æœªæ‰¾åˆ°A4å®éªŒæ•°æ®ï¼")
        return
    
    print(f"\nâœ… æˆåŠŸåŠ è½½ {len(experiments)} ä¸ªå®éªŒ")
    
    # ä¸ºæ¯ä¸ªå®éªŒè®¾ç½®ç®€çŸ­çš„æ˜¾ç¤ºåç§°
    for exp in experiments:
        exp.display_name = parse_reward_name(exp.exp_name)
    
    # è®¡ç®—æŒ‡æ ‡
    print(f"\nğŸ“Š è®¡ç®—æ€§èƒ½æŒ‡æ ‡...")
    exps_with_eval = []
    for exp in experiments:
        metrics = calculate_all_metrics(exp.timesteps, exp.results, exp.ep_lengths)
        exp.metrics = metrics
        
        if exp.eval_data:
            exps_with_eval.append(exp)
            eval_metrics = extract_eval_metrics(exp.eval_data)
            print(f"  {exp.display_name}: eval_success={eval_metrics['eval_success_rate']*100:.1f}%")
    
    print(f"\n  âœ… {len(exps_with_eval)}/{len(experiments)} ä¸ªå®éªŒåŒ…å«evalæ•°æ®")
    
    # æŒ‰å¥–åŠ±å‡½æ•°åˆ†ç»„
    reward_types = {}
    for exp in experiments:
        reward_name = exp.display_name
        if reward_name not in reward_types:
            reward_types[reward_name] = []
        reward_types[reward_name].append(exp)
    
    print(f"\næŒ‰å¥–åŠ±å‡½æ•°åˆ†ç»„:")
    for reward, exps in sorted(reward_types.items()):
        print(f"  {reward}: {len(exps)} ä¸ªå®éªŒ")
    
    configure_plot_style()
    
    print(f"\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    
    # å›¾1: å­¦ä¹ æ›²çº¿å¯¹æ¯”
    print(f"\n  [1/4] å­¦ä¹ æ›²çº¿å¯¹æ¯”...")
    plot_learning_curves(
        experiments,
        group_by='display_name',
        title='Learning Curves: Reward Functions',
        ylabel='Average Return',
        save_path=str(figures_dir / 'a4_learning_curves.png'),
        figsize=(10, 6)
    )
    
    # å›¾2: Evalæ€§èƒ½å¯¹æ¯”ï¼ˆ4ä¸ªå­å›¾ï¼‰
    if exps_with_eval:
        print(f"  [2/4] Evalæ€§èƒ½å¯¹æ¯”...")
        
        metrics_to_plot = {
            'Success Rate': 'eval_success_rate',
            'Collision Rate': 'eval_collision_rate',
            'Path Length (m)': 'eval_mean_path_length',
            'Energy Consumption': 'eval_mean_energy'
        }
        
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        axes = axes.flatten()
        
        for idx, (metric_name, metric_key) in enumerate(metrics_to_plot.items()):
            ax = axes[idx]
            
            reward_names = sorted(reward_types.keys())
            values = []
            errors = []
            
            for reward_name in reward_names:
                reward_exps = [e for e in reward_types[reward_name] if e.eval_data is not None]
                if reward_exps:
                    metric_values = [extract_eval_metrics(e.eval_data)[metric_key] for e in reward_exps]
                    values.append(np.mean(metric_values))
                    errors.append(np.std(metric_values) if len(metric_values) > 1 else 0)
                else:
                    values.append(0)
                    errors.append(0)
            
            # ç»˜åˆ¶æŸ±çŠ¶å›¾
            bars = ax.bar(range(len(reward_names)), values, yerr=errors, 
                          capsize=5, alpha=0.7, edgecolor='black')
            
            # è®¾ç½®é¢œè‰²
            colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6']
            for bar, color in zip(bars, colors[:len(bars)]):
                bar.set_color(color)
            
            ax.set_xticks(range(len(reward_names)))
            ax.set_xticklabels(reward_names, rotation=45, ha='right')
            ax.set_ylabel(metric_name, fontweight='bold')
            ax.set_title(metric_name, fontsize=12, fontweight='bold')
            ax.grid(True, alpha=0.3, axis='y')
            
            # åœ¨æŸ±å­ä¸Šæ˜¾ç¤ºæ•°å€¼
            for i, (v, e) in enumerate(zip(values, errors)):
                if metric_name == 'Success Rate' or metric_name == 'Collision Rate':
                    ax.text(i, v + e + 0.02, f'{v*100:.1f}%', ha='center', va='bottom', fontsize=9)
                else:
                    ax.text(i, v + e + 0.5, f'{v:.1f}', ha='center', va='bottom', fontsize=9)
        
        plt.suptitle('Reward Functions: Evaluation Performance Comparison', 
                     fontsize=14, fontweight='bold', y=0.995)
        plt.tight_layout()
        plt.savefig(str(figures_dir / 'a4_eval_performance.png'), dpi=300, bbox_inches='tight')
        plt.close()
        print(f"    âœ… ä¿å­˜: a4_eval_performance.png")
    
    # å›¾3: å¤šç»´åº¦é›·è¾¾å›¾
    if exps_with_eval:
        print(f"  [3/4] å¤šç»´åº¦é›·è¾¾å›¾...")
        
        # å‡†å¤‡é›·è¾¾å›¾æ•°æ®
        categories = ['Success\nRate', 'Safety\n(1-Collision)', 'Path\nEfficiency', 
                     'Smoothness', 'Energy\nEfficiency']
        
        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))
        
        angles = np.linspace(0, 2*np.pi, len(categories), endpoint=False).tolist()
        angles += angles[:1]  # é—­åˆå›¾å½¢
        
        colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6']
        
        for idx, (reward_name, reward_exps) in enumerate(sorted(reward_types.items())):
            eval_exps = [e for e in reward_exps if e.eval_data is not None]
            if not eval_exps:
                continue
            
            # è®¡ç®—å„ç»´åº¦æŒ‡æ ‡
            metrics_list = [extract_eval_metrics(e.eval_data) for e in eval_exps]
            
            success_rate = np.mean([m['eval_success_rate'] for m in metrics_list])
            safety = 1 - np.mean([m['eval_collision_rate'] for m in metrics_list])
            path_eff = np.mean([15.0 / max(m['eval_mean_path_length'], 15.0) for m in metrics_list])
            smoothness = np.mean([1.0 - m['eval_mean_smoothness'] / 10.0 for m in metrics_list])  # åè½¬ï¼šè¶Šå°è¶Šå¥½å˜ä¸ºè¶Šå¤§è¶Šå¥½
            energy_eff = np.mean([1.0 / (1.0 + m['eval_mean_energy'] / 100.0) for m in metrics_list])
            
            values = [success_rate, safety, path_eff, smoothness, energy_eff]
            values += values[:1]
            
            ax.plot(angles, values, 'o-', linewidth=2, label=reward_name, 
                   color=colors[idx % len(colors)])
            ax.fill(angles, values, alpha=0.15, color=colors[idx % len(colors)])
        
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(categories, size=11, fontweight='bold')
        ax.set_ylim(0, 1)
        ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])
        ax.set_yticklabels(['20%', '40%', '60%', '80%', '100%'])
        ax.grid(True, alpha=0.3)
        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=10)
        
        plt.title('Reward Functions: Multi-dimensional Performance', 
                 size=14, fontweight='bold', pad=20)
        plt.tight_layout()
        plt.savefig(str(figures_dir / 'a4_radar.png'), dpi=300, bbox_inches='tight')
        plt.close()
        print(f"    âœ… ä¿å­˜: a4_radar.png")
    
    # å›¾4: æ ·æœ¬æ•ˆç‡å¯¹æ¯”
    print(f"  [4/4] æ ·æœ¬æ•ˆç‡å¯¹æ¯”...")
    
    fig, ax = plt.subplots(figsize=(10, 6))
    
    reward_names = sorted(reward_types.keys())
    efficiency_values = []
    
    for reward_name in reward_names:
        reward_exps = reward_types[reward_name]
        eff_list = [e.metrics['sample_efficiency'] for e in reward_exps 
                   if e.metrics['sample_efficiency'] is not None]
        if eff_list:
            efficiency_values.append(np.mean(eff_list) / 1000)  # è½¬æ¢ä¸ºK
        else:
            efficiency_values.append(None)
    
    # ç»˜åˆ¶æŸ±çŠ¶å›¾
    x_pos = range(len(reward_names))
    colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6']
    bars = ax.bar(x_pos, [v if v else 0 for v in efficiency_values], 
                  alpha=0.7, edgecolor='black')
    
    for bar, color in zip(bars, colors[:len(bars)]):
        bar.set_color(color)
    
    # åœ¨æŸ±å­ä¸Šæ ‡æ³¨æ•°å€¼
    for i, v in enumerate(efficiency_values):
        if v:
            ax.text(i, v + 5, f'{v:.0f}K', ha='center', va='bottom', 
                   fontsize=10, fontweight='bold')
    
    ax.set_xticks(x_pos)
    ax.set_xticklabels(reward_names, fontsize=11)
    ax.set_ylabel('Training Steps to 80% of Max Return (K)', fontsize=12, fontweight='bold')
    ax.set_title('Sample Efficiency: Reward Functions', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    plt.savefig(str(figures_dir / 'a4_sample_efficiency.png'), dpi=300, bbox_inches='tight')
    plt.close()
    print(f"    âœ… ä¿å­˜: a4_sample_efficiency.png")
    plt.close()
    print(f"    âœ… ä¿å­˜: a4_sample_efficiency.png")
    
    # ç”Ÿæˆæ±‡æ€»è¡¨
    print(f"\nğŸ“„ ç”Ÿæˆæ±‡æ€»è¡¨æ ¼...")
    summary_data = []
    for exp in experiments:
        eval_metrics = {}
        if exp.eval_data:
            eval_metrics = extract_eval_metrics(exp.eval_data)
        
        summary_data.append({
            'Experiment': exp.display_name,
            'Algorithm': exp.algorithm,
            'Final_Return': exp.metrics['final_mean'],
            'Peak_Value': exp.metrics['peak_value'],
            'Sample_Efficiency': exp.metrics['sample_efficiency'],
            'Training_Stability': exp.metrics['training_stability'],
            'Eval_Success_Rate': eval_metrics.get('eval_success_rate', np.nan),
            'Eval_Collision_Rate': eval_metrics.get('eval_collision_rate', np.nan),
            'Eval_Path_Length': eval_metrics.get('eval_mean_path_length', np.nan),
            'Eval_Energy': eval_metrics.get('eval_mean_energy', np.nan),
        })
    
    df = pd.DataFrame(summary_data)
    summary_csv = output_dir / 'a4_detailed_summary.csv'
    df.to_csv(summary_csv, index=False, float_format='%.4f')
    print(f"  æ±‡æ€»è¡¨: {summary_csv}")
    
    # ç”ŸæˆæŠ¥å‘Š
    print(f"\nğŸ“ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
    report_path = output_dir / 'a4_report.md'
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("# A4å®éªŒç»„åˆ†ææŠ¥å‘Šï¼šå¥–åŠ±å‡½æ•°å¯¹æ¯”\n\n")
        f.write("**å®éªŒç›®æ ‡**: åˆ†æä¸åŒå¥–åŠ±å‡½æ•°è®¾è®¡å¯¹è®­ç»ƒæ•ˆæœçš„å½±å“\n\n")
        f.write("---\n\n")
        
        f.write("## 1. å®éªŒæ¦‚è§ˆ\n\n")
        f.write(f"- **æ€»å®éªŒæ•°**: {len(experiments)}\n")
        f.write(f"- **å¥–åŠ±å‡½æ•°å˜ä½“**: {', '.join(sorted(reward_types.keys()))}\n")
        f.write(f"- **åŒ…å«Evalæ•°æ®**: {len(exps_with_eval)}/{len(experiments)}\n")
        f.write(f"- **ç®—æ³•**: SAC (å›ºå®š)\n\n")
        
        f.write("### å¥–åŠ±å‡½æ•°è®¾è®¡\n\n")
        f.write("- **Baseline**: å¹³è¡¡çš„å¥–åŠ±è®¾è®¡ï¼ŒåŒ…å«æ‰€æœ‰ç»„ä»¶\n")
        f.write("- **Sparse**: ä»…ä¾èµ–ç»ˆæ­¢å¥–åŠ±ï¼ˆæˆåŠŸ/ç¢°æ’ï¼‰ï¼Œæ— ä¸­é—´å¼•å¯¼\n")
        f.write("- **Dense**: å¼ºåŒ–è¿›åº¦å¥–åŠ±å’Œæ—¶é—´æƒ©ç½šï¼ŒåŠ å¿«å­¦ä¹ \n")
        f.write("- **NoStep**: ç§»é™¤æ—¶é—´å‹åŠ›ï¼Œè®©æ™ºèƒ½ä½“æœ‰æ›´å¤šæ—¶é—´æ¢ç´¢\n")
        f.write("- **Energy**: å¼ºåŒ–èƒ½é‡æ•ˆç‡ï¼Œé¼“åŠ±å¹³æ»‘æ§åˆ¶\n\n")
        
        f.write("---\n\n")
        
        f.write("## 2. å¯è§†åŒ–åˆ†æ\n\n")
        
        f.write("### 2.1 å­¦ä¹ æ›²çº¿å¯¹æ¯”\n\n")
        f.write("![Learning Curves](figures/a4_learning_curves.png)\n\n")
        f.write("å±•ç¤ºä¸åŒå¥–åŠ±å‡½æ•°ä¸‹çš„è®­ç»ƒè¿‡ç¨‹å’Œæ”¶æ•›é€Ÿåº¦ã€‚\n\n")
        
        f.write("### 2.2 Evalæ€§èƒ½å¯¹æ¯”\n\n")
        f.write("![Eval Performance](figures/a4_eval_performance.png)\n\n")
        f.write("åŸºäº100ä¸ªç‹¬ç«‹è¯„ä¼°episodesçš„æ€§èƒ½å¯¹æ¯”ï¼ˆæˆåŠŸç‡ã€ç¢°æ’ç‡ã€è·¯å¾„é•¿åº¦ã€èƒ½é‡æ¶ˆè€—ï¼‰ã€‚\n\n")
        
        f.write("### 2.3 å¤šç»´åº¦é›·è¾¾å›¾\n\n")
        f.write("![Radar Chart](figures/a4_radar.png)\n\n")
        f.write("ç»¼åˆè¯„ä¼°å„å¥–åŠ±å‡½æ•°åœ¨å¤šä¸ªç»´åº¦çš„è¡¨ç°ï¼š\n")
        f.write("- Success Rate: ä»»åŠ¡æˆåŠŸç‡\n")
        f.write("- Safety: å®‰å…¨æ€§ (1 - ç¢°æ’ç‡)\n")
        f.write("- Path Efficiency: è·¯å¾„æ•ˆç‡\n")
        f.write("- Smoothness: è·¯å¾„å¹³æ»‘åº¦\n")
        f.write("- Energy Efficiency: èƒ½é‡æ•ˆç‡\n\n")
        
        f.write("### 2.4 æ ·æœ¬æ•ˆç‡å¯¹æ¯”\n\n")
        f.write("![Sample Efficiency](figures/a4_sample_efficiency.png)\n\n")
        f.write("è¾¾åˆ°æœ€å¤§å›æŠ¥80%æ‰€éœ€çš„è®­ç»ƒæ­¥æ•°ï¼ˆè¶Šå°‘è¶Šå¥½ï¼‰ã€‚\n\n")
        
        f.write("---\n\n")
        
        f.write("## 3. ä¸»è¦å‘ç°\n\n")
        f.write("### 3.1 æ€§èƒ½æ’åº\n\n")
        f.write("*(è¯·æ ¹æ®ç”Ÿæˆçš„å›¾è¡¨å¡«å†™å…³é”®å‘ç°)*\n\n")
        f.write("**æˆåŠŸç‡**: ...\n\n")
        f.write("**å­¦ä¹ é€Ÿåº¦**: ...\n\n")
        f.write("**è®­ç»ƒç¨³å®šæ€§**: ...\n\n")
        
        f.write("### 3.2 å¥–åŠ±å‡½æ•°å½±å“åˆ†æ\n\n")
        f.write("- **Sparseå¥–åŠ±**: ...\n")
        f.write("- **Denseå¥–åŠ±**: ...\n")
        f.write("- **NoStepå¥–åŠ±**: ...\n")
        f.write("- **Energyå¥–åŠ±**: ...\n\n")
        
        f.write("### 3.3 æ¨èé…ç½®\n\n")
        f.write("æ ¹æ®å®éªŒç»“æœï¼Œæ¨èä½¿ç”¨ **[...]** å¥–åŠ±å‡½æ•°ï¼Œå› ä¸º...\n\n")
        
        f.write("---\n\n")
        
        f.write("## 4. æ•°æ®è¡¨æ ¼\n\n")
        f.write(f"å®Œæ•´æ•°æ®è¯·æŸ¥çœ‹: `a4_detailed_summary.csv`\n\n")
        f.write("```\n")
        f.write(df.to_string(index=False))
        f.write("\n```\n\n")
        
        f.write("---\n\n")
        f.write(f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {pd.Timestamp.now()}*\n")
    
    print(f"  åˆ†ææŠ¥å‘Š: {report_path}")
    
    print("\n" + "="*80)
    print("âœ… A4å®éªŒç»„åˆ†æå®Œæˆï¼")
    print("="*80)
    print()


if __name__ == '__main__':
    main()
