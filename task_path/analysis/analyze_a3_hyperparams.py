"""A3å®éªŒç»„åˆ†æï¼šè¶…å‚æ•°æ•æ„Ÿæ€§

åˆ†æä¸åŒè¶…å‚æ•°å¯¹å„ç®—æ³•æ€§èƒ½çš„å½±å“
"""

import os
import sys
import re
import numpy as np
import pandas as pd
from pathlib import Path
from collections import defaultdict
import matplotlib.pyplot as plt

sys.path.insert(0, str(Path(__file__).parent.parent))

from analysis.data_loader import scan_experiment_results, group_experiments_by
from analysis.metrics_calculator import calculate_all_metrics, extract_eval_metrics
from analysis.visualization import (
    plot_learning_curves,
    configure_plot_style,
)


def parse_hyperparam_from_name(exp_name: str) -> tuple:
    """ä»å®éªŒåç§°è§£æè¶…å‚æ•°ç±»å‹å’Œå€¼
    
    Returns:
        (param_type, param_value, display_name)
    """
    # ç§»é™¤æ—¶é—´æˆ³éƒ¨åˆ†
    name_parts = exp_name.split('_')
    
    # æ‰¾åˆ°è¶…å‚æ•°éƒ¨åˆ†ï¼ˆä¸å«æ—¶é—´æˆ³ï¼‰
    hyperparam_part = None
    for part in name_parts:
        if any(x in part for x in ['lr', 'batch', 'clip', 'ep', 'buf', 'ent', 'delay', 'noise']):
            hyperparam_part = part
            break
    
    if not hyperparam_part:
        return ('unknown', 'unknown', exp_name)
    
    # è§£æä¸åŒç±»å‹çš„è¶…å‚æ•°
    if hyperparam_part.startswith('lr'):
        # lr1e4, lr3e4, lr1e3 -> Learning Rate
        value = hyperparam_part[2:]
        if 'e' in value:
            # è½¬æ¢ç§‘å­¦è®¡æ•°æ³•
            numeric_value = float(value.replace('e', 'e-'))
            display_name = f'LR={numeric_value:.0e}'
        else:
            display_name = f'LR={value}'
        return ('Learning Rate', value, display_name)
    
    elif hyperparam_part.startswith('batch'):
        # batch32, batch64 -> Batch Size
        value = hyperparam_part[5:]
        return ('Batch Size', value, f'Batch={value}')
    
    elif hyperparam_part.startswith('clip'):
        # clip01, clip02, clip03 -> Clip Range (éœ€è¦è½¬æ¢ä¸º0.1, 0.2, 0.3)
        value = hyperparam_part[4:]
        actual_value = float(value) / 10  # 01->0.1, 02->0.2
        return ('Clip Range', value, f'Clip={actual_value:.1f}')
    
    elif hyperparam_part.startswith('ep'):
        # ep5, ep10, ep15, ep20 -> Epochs
        value = hyperparam_part[2:]
        return ('Epochs', value, f'Epochs={value}')
    
    elif hyperparam_part.startswith('buf'):
        # buf100k, buf500k, buf1m, buf2m -> Buffer Size
        value = hyperparam_part[3:]
        if 'k' in value:
            display_value = value.upper()
        elif 'm' in value:
            display_value = value.upper()
        else:
            display_value = value
        return ('Buffer Size', value, f'Buffer={display_value}')
    
    elif hyperparam_part.startswith('ent'):
        # ent01, ent03, ent05, ent_auto -> Entropy Coef
        value = hyperparam_part[3:]
        if 'auto' in value or value == '' or value.startswith('_'):
            display_name = 'Ent=auto'
            actual_value = 'auto'
        else:
            actual_value = float(value) / 10
            display_name = f'Ent={actual_value:.1f}'
        return ('Entropy Coef', value if value else 'auto', display_name)
    
    elif hyperparam_part.startswith('delay'):
        # delay1, delay2, delay3 -> Policy Delay
        value = hyperparam_part[5:]
        return ('Policy Delay', value, f'Delay={value}')
    
    elif hyperparam_part.startswith('noise'):
        # noise01, noise02, noise03 -> Target Noise
        value = hyperparam_part[5:]
        actual_value = float(value) / 10
        return ('Target Noise', value, f'Noise={actual_value:.1f}')
    
    return ('unknown', hyperparam_part, hyperparam_part)


def get_hyperparam_sort_key(param_type: str, param_value: str) -> float:
    """è·å–è¶…å‚æ•°çš„æ’åºé”®å€¼ï¼ˆç”¨äºæ¨ªåæ ‡æ’åºï¼‰"""
    try:
        # Learning Rate: 1e4, 3e4, 1e3
        if param_type == 'Learning Rate':
            return float(param_value.replace('e', 'e-'))
        
        # Clip Range: 01, 02, 03 -> 0.1, 0.2, 0.3
        elif param_type == 'Clip Range':
            return float(param_value) / 10
        
        # Entropy: 01, 03, 05, auto
        elif param_type == 'Entropy Coef':
            if 'auto' in str(param_value) or param_value == '':
                return -1  # autoæ”¾åœ¨æœ€å‰é¢
            try:
                return float(param_value) / 10
            except:
                return -1
        
        # Target Noise: 01, 02, 03
        elif param_type == 'Target Noise':
            return float(param_value) / 10
        
        # Buffer Size: 100k, 500k, 1m, 1500k, 2m
        elif param_type == 'Buffer Size':
            if 'k' in param_value:
                return float(param_value.replace('k', '')) * 1000
            elif 'm' in param_value:
                return float(param_value.replace('m', '')) * 1000000
            return float(param_value)
        
        # å…¶ä»–ï¼šç›´æ¥è½¬æ•°å­—
        else:
            return float(param_value)
    except:
        return 0


def plot_hyperparam_sensitivity_line(experiments, param_type, algo, save_path, figsize=(10, 6)):
    """ç»˜åˆ¶è¶…å‚æ•°æ•æ„Ÿæ€§æŠ˜çº¿å›¾ï¼ˆåŒçºµè½´ï¼šæˆåŠŸç‡+ç¢°æ’ç‡ï¼‰"""
    
    # æå–æ•°æ®
    data_points = []
    for exp in experiments:
        ptype, pvalue, display_name = parse_hyperparam_from_name(exp.exp_name)
        if ptype == param_type and exp.eval_data:
            eval_metrics = extract_eval_metrics(exp.eval_data)
            sort_key = get_hyperparam_sort_key(param_type, pvalue)
            data_points.append({
                'sort_key': sort_key,
                'display_name': display_name,
                'success_rate': eval_metrics['eval_success_rate'] * 100,  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
                'collision_rate': eval_metrics['eval_collision_rate'] * 100,
            })
    
    if not data_points:
        print(f"    âš ï¸ {param_type}: æ— æœ‰æ•ˆæ•°æ®")
        return
    
    # æŒ‰sort_keyæ’åº
    data_points.sort(key=lambda x: x['sort_key'])
    
    # æå–æ•°æ®
    x_labels = [d['display_name'] for d in data_points]
    success_rates = [d['success_rate'] for d in data_points]
    collision_rates = [d['collision_rate'] for d in data_points]
    
    # ç»˜å›¾
    fig, ax1 = plt.subplots(figsize=figsize)
    
    # å·¦ä¾§Yè½´ï¼šæˆåŠŸç‡ï¼ˆç»¿è‰²ï¼‰
    color1 = '#2ecc71'
    ax1.set_xlabel(param_type, fontsize=12, fontweight='bold')
    ax1.set_ylabel('Success Rate (%)', color=color1, fontsize=12, fontweight='bold')
    line1 = ax1.plot(x_labels, success_rates, color=color1, marker='o', 
                      linewidth=2, markersize=8, label='Success Rate')
    ax1.tick_params(axis='y', labelcolor=color1)
    ax1.grid(True, alpha=0.3, linestyle='--')
    ax1.set_ylim([0, 100])
    
    # å³ä¾§Yè½´ï¼šç¢°æ’ç‡ï¼ˆçº¢è‰²ï¼‰
    ax2 = ax1.twinx()
    color2 = '#e74c3c'
    ax2.set_ylabel('Collision Rate (%)', color=color2, fontsize=12, fontweight='bold')
    line2 = ax2.plot(x_labels, collision_rates, color=color2, marker='s', 
                      linewidth=2, markersize=8, label='Collision Rate')
    ax2.tick_params(axis='y', labelcolor=color2)
    ax2.set_ylim([0, 100])
    
    # æ ‡é¢˜
    plt.title(f'{algo.upper()} - {param_type} Sensitivity', 
              fontsize=14, fontweight='bold', pad=20)
    
    # åˆå¹¶å›¾ä¾‹
    lines = line1 + line2
    labels = [l.get_label() for l in lines]
    ax1.legend(lines, labels, loc='upper left', frameon=True, shadow=True)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"    âœ… {param_type}: {save_path}")


def plot_hyperparam_learning_curves(experiments, param_type, algo, save_path, figsize=(12, 8)):
    """ç»˜åˆ¶ä¸åŒè¶…å‚æ•°å€¼ä¸‹çš„å­¦ä¹ æ›²çº¿å¯¹æ¯”ï¼ˆå­å›¾å½¢å¼ï¼‰"""
    
    # æŒ‰è¶…å‚æ•°å€¼åˆ†ç»„
    param_groups = defaultdict(list)
    for exp in experiments:
        ptype, pvalue, display_name = parse_hyperparam_from_name(exp.exp_name)
        if ptype == param_type:
            param_groups[param_type].append(exp)
            exp.display_name = display_name  # è®¾ç½®æ˜¾ç¤ºåç§°
            # è°ƒè¯•ï¼šè¾“å‡ºdisplay_name
            if param_type == 'Buffer Size':
                print(f"      - {exp.exp_name.split('_2026')[0]}: display_name='{display_name}'")
    
    if not param_groups[param_type]:
        print(f"    âš ï¸ {param_type}: æ— å­¦ä¹ æ›²çº¿æ•°æ®")
        return
    
    # ä½¿ç”¨visualizationæ¨¡å—çš„å‡½æ•°ç»˜åˆ¶å­¦ä¹ æ›²çº¿
    plot_learning_curves(
        param_groups[param_type],
        group_by='display_name',
        title=f'{algo.upper()} - {param_type} Learning Curves',
        ylabel='Average Return',
        save_path=save_path,
        figsize=figsize
    )
    print(f"    âœ… {param_type}å­¦ä¹ æ›²çº¿: {save_path}")


def main():
    """ä¸»å‡½æ•°ï¼šA3è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æ"""
    
    print("="*80)
    print("A3 å®éªŒç»„åˆ†æï¼šè¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æ")
    print("="*80)
    
    # é…ç½®è·¯å¾„
    results_dir = Path(__file__).parent.parent / 'results'
    a3_dir = results_dir / 'a3'
    output_dir = a3_dir / 'analysis'
    figures_dir = output_dir / 'figures'
    
    output_dir.mkdir(parents=True, exist_ok=True)
    figures_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"\nğŸ“‚ åŠ è½½å®éªŒæ•°æ®...")
    experiments = scan_experiment_results(str(results_dir), experiment_group='a3')
    
    if not experiments:
        print("âŒ æœªæ‰¾åˆ°A3å®éªŒæ•°æ®ï¼")
        return
    
    print(f"\nâœ… æˆåŠŸåŠ è½½ {len(experiments)} ä¸ªå®éªŒ")
    
    # è®¡ç®—æŒ‡æ ‡
    print(f"\nğŸ“Š è®¡ç®—æ€§èƒ½æŒ‡æ ‡...")
    exps_with_eval = []
    for exp in experiments:
        metrics = calculate_all_metrics(exp.timesteps, exp.results, exp.ep_lengths)
        exp.metrics = metrics
        
        if exp.eval_data:
            exps_with_eval.append(exp)
            eval_metrics = extract_eval_metrics(exp.eval_data)
            print(f"  {exp.exp_name.split('_2026')[0]}: eval_success={eval_metrics['eval_success_rate']*100:.1f}%")
    
    print(f"\n  âœ… {len(exps_with_eval)}/{len(experiments)} ä¸ªå®éªŒåŒ…å«evalæ•°æ®")
    
    # æŒ‰ç®—æ³•åˆ†ç»„
    exps_by_algo = group_experiments_by(experiments, by='algorithm')
    
    print(f"\næŒ‰ç®—æ³•åˆ†ç»„:")
    for algo, exps in sorted(exps_by_algo.items()):
        print(f"  {algo}: {len(exps)} ä¸ªå®éªŒ")
    
    configure_plot_style()
    
    # å®šä¹‰æ¯ä¸ªç®—æ³•éœ€è¦åˆ†æçš„è¶…å‚æ•°
    algo_params = {
        'PPO': ['Learning Rate', 'Batch Size', 'Clip Range', 'Epochs'],
        'SAC': ['Learning Rate', 'Batch Size', 'Buffer Size', 'Entropy Coef'],
        'TD3': ['Learning Rate', 'Policy Delay', 'Target Noise']
    }
    
    print(f"\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    
    # ä¸ºæ¯ä¸ªç®—æ³•ç”Ÿæˆå›¾è¡¨
    for algo_idx, (algo, algo_exps) in enumerate(sorted(exps_by_algo.items())):
        print(f"\n{'='*60}")
        print(f"ğŸ“Š [{algo_idx+1}/{len(exps_by_algo)}] {algo}è¶…å‚æ•°åˆ†æ")
        print(f"{'='*60}")
        
        if algo.upper() not in algo_params:
            print(f"  âš ï¸ æœªå®šä¹‰{algo}çš„è¶…å‚æ•°åˆ—è¡¨")
            continue
        
        params_to_analyze = algo_params[algo.upper()]
        
        for param_idx, param_type in enumerate(params_to_analyze):
            print(f"\n  [{param_idx+1}/{len(params_to_analyze)}] {param_type}:")
            
            # è¿‡æ»¤å‡ºè¯¥è¶…å‚æ•°ç±»å‹çš„å®éªŒ
            param_exps = []
            for exp in algo_exps:
                ptype, _, _ = parse_hyperparam_from_name(exp.exp_name)
                if ptype == param_type:
                    param_exps.append(exp)
            
            if not param_exps:
                print(f"    âš ï¸ æ— {param_type}å®éªŒ")
                continue
            
            print(f"    æ‰¾åˆ° {len(param_exps)} ä¸ªå®éªŒ")
            
            # 1. æ•æ„Ÿæ€§æŠ˜çº¿å›¾ï¼ˆæˆåŠŸç‡+ç¢°æ’ç‡ï¼‰
            safe_param_name = param_type.lower().replace(' ', '_')
            plot_hyperparam_sensitivity_line(
                param_exps,
                param_type,
                algo,
                save_path=str(figures_dir / f'a3_{algo.lower()}_{safe_param_name}_sensitivity.png'),
                figsize=(10, 6)
            )
            
            # 2. å­¦ä¹ æ›²çº¿å¯¹æ¯”
            plot_hyperparam_learning_curves(
                param_exps,
                param_type,
                algo,
                save_path=str(figures_dir / f'a3_{algo.lower()}_{safe_param_name}_learning.png'),
                figsize=(10, 6)
            )
    
    # ç”Ÿæˆæ±‡æ€»è¡¨
    print(f"\nğŸ“„ ç”Ÿæˆæ±‡æ€»è¡¨æ ¼...")
    summary_data = []
    for exp in experiments:
        ptype, pvalue, display_name = parse_hyperparam_from_name(exp.exp_name)
        
        eval_metrics = {}
        if exp.eval_data:
            eval_metrics = extract_eval_metrics(exp.eval_data)
        
        summary_data.append({
            'Experiment': exp.exp_name.split('_2026')[0],  # ç§»é™¤æ—¶é—´æˆ³
            'Algorithm': exp.algorithm,
            'Hyperparam_Type': ptype,
            'Hyperparam_Display': display_name,
            'Final_Return': exp.metrics['final_mean'],
            'Sample_Efficiency': exp.metrics['sample_efficiency'],
            'Eval_Success_Rate': eval_metrics.get('eval_success_rate', np.nan),
            'Eval_Collision_Rate': eval_metrics.get('eval_collision_rate', np.nan),
            'Eval_Path_Length': eval_metrics.get('eval_mean_path_length', np.nan),
            'Eval_Energy': eval_metrics.get('eval_mean_energy', np.nan),
        })
    
    df = pd.DataFrame(summary_data)
    summary_csv = output_dir / 'a3_detailed_summary.csv'
    df.to_csv(summary_csv, index=False, float_format='%.4f')
    print(f"  æ±‡æ€»è¡¨: {summary_csv}")
    
    # ç”ŸæˆæŠ¥å‘Š
    print(f"\nğŸ“ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
    report_path = output_dir / 'a3_report.md'
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("# A3å®éªŒç»„åˆ†ææŠ¥å‘Šï¼šè¶…å‚æ•°æ•æ„Ÿæ€§\n\n")
        f.write("**å®éªŒç›®æ ‡**: åˆ†æè¶…å‚æ•°å¯¹ç®—æ³•æ€§èƒ½çš„å½±å“\n\n")
        f.write("---\n\n")
        
        f.write("## 1. å®éªŒæ¦‚è§ˆ\n\n")
        f.write(f"- **æ€»å®éªŒæ•°**: {len(experiments)}\n")
        f.write(f"- **ç®—æ³•**: {', '.join(sorted(exps_by_algo.keys()))}\n")
        f.write(f"- **åŒ…å«Evalæ•°æ®**: {len(exps_with_eval)}/{len(experiments)}\n\n")
        
        # æŒ‰ç®—æ³•ç»Ÿè®¡å®éªŒæ•°
        f.write("### å„ç®—æ³•å®éªŒåˆ†å¸ƒ\n\n")
        for algo, exps in sorted(exps_by_algo.items()):
            f.write(f"- **{algo}**: {len(exps)}ä¸ªå®éªŒ\n")
            
            # ç»Ÿè®¡è¯¥ç®—æ³•æµ‹è¯•çš„è¶…å‚æ•°ç±»å‹
            param_types = set()
            for exp in exps:
                ptype, _, _ = parse_hyperparam_from_name(exp.exp_name)
                if ptype != 'unknown':
                    param_types.add(ptype)
            f.write(f"  - æµ‹è¯•è¶…å‚æ•°: {', '.join(sorted(param_types))}\n")
        
        f.write("\n---\n\n")
        
        f.write("## 2. è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æ\n\n")
        f.write("### 2.1 å›¾è¡¨è¯´æ˜\n\n")
        f.write("æ¯ä¸ªç®—æ³•ç”Ÿæˆä¸¤ç±»å›¾è¡¨ï¼š\n\n")
        f.write("1. **æ•æ„Ÿæ€§æŠ˜çº¿å›¾** (`*_sensitivity.png`)\n")
        f.write("   - æ¨ªåæ ‡ï¼šè¶…å‚æ•°å€¼\n")
        f.write("   - å·¦ä¾§çºµåæ ‡ï¼ˆç»¿è‰²ï¼‰ï¼šæˆåŠŸç‡ (%)\n")
        f.write("   - å³ä¾§çºµåæ ‡ï¼ˆçº¢è‰²ï¼‰ï¼šç¢°æ’ç‡ (%)\n")
        f.write("   - ç”¨äºè§‚å¯Ÿè¶…å‚æ•°å˜åŒ–å¯¹æ€§èƒ½å’Œå®‰å…¨æ€§çš„å½±å“\n\n")
        
        f.write("2. **å­¦ä¹ æ›²çº¿å¯¹æ¯”** (`*_learning.png`)\n")
        f.write("   - å±•ç¤ºä¸åŒè¶…å‚æ•°å€¼ä¸‹çš„è®­ç»ƒè¿‡ç¨‹\n")
        f.write("   - ç”¨äºè§‚å¯Ÿå­¦ä¹ é€Ÿåº¦å’Œæ”¶æ•›è¡Œä¸ºçš„å·®å¼‚\n\n")
        
        f.write("### 2.2 å›¾è¡¨åˆ—è¡¨\n\n")
        f.write("è¯¦ç»†å›¾è¡¨è¯·æŸ¥çœ‹ `figures/` ç›®å½•ï¼š\n\n")
        
        for algo in sorted(exps_by_algo.keys()):
            f.write(f"#### {algo}\n\n")
            if algo.upper() in algo_params:
                for param in algo_params[algo.upper()]:
                    safe_name = param.lower().replace(' ', '_')
                    f.write(f"- {param}:\n")
                    f.write(f"  - æ•æ„Ÿæ€§: `a3_{algo.lower()}_{safe_name}_sensitivity.png`\n")
                    f.write(f"  - å­¦ä¹ æ›²çº¿: `a3_{algo.lower()}_{safe_name}_learning.png`\n")
            f.write("\n")
        
        f.write("---\n\n")
        
        f.write("## 3. ä¸»è¦å‘ç°\n\n")
        f.write("### 3.1 è¶…å‚æ•°æ•æ„Ÿæ€§æ’åº\n\n")
        f.write("*(è¯·æ ¹æ®ç”Ÿæˆçš„å›¾è¡¨å¡«å†™å…³é”®å‘ç°)*\n\n")
        f.write("- **PPO**: ...\n")
        f.write("- **SAC**: ...\n")
        f.write("- **TD3**: ...\n\n")
        
        f.write("### 3.2 æœ€ä¼˜è¶…å‚æ•°é…ç½®\n\n")
        f.write("åŸºäºå®éªŒç»“æœï¼Œæ¨èçš„è¶…å‚æ•°é…ç½®ï¼š\n\n")
        f.write("*(è¯·æ ¹æ®æ•æ„Ÿæ€§å›¾è¡¨å¡«å†™æœ€ä¼˜é…ç½®)*\n\n")
        
        f.write("---\n\n")
        
        f.write("## 4. æ•°æ®è¡¨æ ¼\n\n")
        f.write(f"å®Œæ•´æ•°æ®è¯·æŸ¥çœ‹: `a3_detailed_summary.csv`\n\n")
        
        # å±•ç¤ºå‰10è¡Œæ•°æ®ï¼ˆä¸ä½¿ç”¨to_markdownä»¥é¿å…ä¾èµ–tabulateï¼‰
        f.write("### ç¤ºä¾‹æ•°æ®ï¼ˆå‰10è¡Œï¼‰\n\n")
        f.write("```\n")
        f.write(df.head(10).to_string(index=False))
        f.write("\n```\n\n")
        
        f.write("---\n\n")
        f.write(f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {pd.Timestamp.now()}*\n")
    
    print(f"  åˆ†ææŠ¥å‘Š: {report_path}")
    
    print("\n" + "="*80)
    print("âœ… A3å®éªŒç»„åˆ†æå®Œæˆï¼")
    print("="*80)
    print()


if __name__ == '__main__':
    main()
