# RL_fish: ä»¿ç”Ÿé±¼å¼ºåŒ–å­¦ä¹ é¡¹ç›®

<div align="center">

å¼ºåŒ–å­¦ä¹ åœ¨æ°´ä¸‹æœºå™¨äººä¸­çš„åº”ç”¨

[![License](https://img.shields.io/badge/License-MIT-yellow.svg)
](LICENSE)

---

## ğŸ¯ é¡¹ç›®ç®€ä»‹

RL_fish æ˜¯ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ é¡¹ç›®ï¼Œä¸“æ³¨äºåœ¨æ°´ä¸‹ç¯å¢ƒä¸­è®­ç»ƒæœºå™¨äººå®Œæˆå„ç§ä»»åŠ¡ï¼ˆç›®å‰ä»…å®ç°äº†ï¼‰ã€‚é¡¹ç›®å®ç°äº†å®Œæ•´çš„å®éªŒæµæ°´çº¿ï¼Œä»ç‰©ç†ä»¿çœŸã€ç¯å¢ƒå»ºæ¨¡åˆ°ç®—æ³•è®­ç»ƒã€æ€§èƒ½è¯„ä¼°å’Œæ•°æ®åˆ†æã€‚

### æ ¸å¿ƒç›®æ ‡

- ğŸŸ **ä»¿ç”Ÿæœºå™¨äººæ§åˆ¶**: æ¨¡æ‹Ÿé±¼ç±»æ¨è¿›åŠ¨åŠ›å­¦ï¼Œå®ç°è‡ªç„¶æµç•…çš„è¿åŠ¨
- ğŸŒŠ **å¤æ‚ç¯å¢ƒå¯¼èˆª**: åœ¨å«éšœç¢ç‰©ã€æ´‹æµç­‰å¤æ‚æ¡ä»¶ä¸‹å®Œæˆè·¯å¾„è§„åˆ’
- ğŸ§  **å¤šç®—æ³•å¯¹æ¯”**: ç³»ç»Ÿè¯„ä¼° PPOã€SACã€TD3 ç­‰ä¸»æµå¼ºåŒ–å­¦ä¹ ç®—æ³•

### é€‚ç”¨åœºæ™¯

- æ°´ä¸‹æœºå™¨äººè‡ªä¸»å¯¼èˆªç ”ç©¶
- å¼ºåŒ–å­¦ä¹ ç®—æ³•æ€§èƒ½è¯„ä¼°
- ç¯å¢ƒå‚æ•°æ•æ„Ÿæ€§åˆ†æ
- å¥–åŠ±å‡½æ•°è®¾è®¡ä¸ä¼˜åŒ–
- è¶…å‚æ•°è°ƒä¼˜å®éªŒ

---

## ğŸ›ï¸ ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Task Layer (åº”ç”¨å±‚)                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚   è®­ç»ƒç³»ç»Ÿ   â”‚  â”‚   è¯„ä¼°ç³»ç»Ÿ    â”‚  â”‚   åˆ†æå·¥å…·é“¾    â”‚    â”‚
â”‚   â”‚  train.py   â”‚  â”‚   eval.py    â”‚  â”‚  analysis/*    â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Environment Layer (ç¯å¢ƒå±‚)                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚         PathPlanning2DEnv (Gymnasium)            â”‚      â”‚
â”‚   â”‚  â€¢ è§‚æµ‹ç©ºé—´: ä½ç½®/é€Ÿåº¦/ç›®æ ‡/æ¿€å…‰é›·è¾¾               â”‚      â”‚
â”‚   â”‚  â€¢ åŠ¨ä½œç©ºé—´: è¿ç»­æ¨åŠ›æ§åˆ¶ [-1,1]Â²                â”‚      â”‚
â”‚   â”‚  â€¢ å¥–åŠ±å‡½æ•°: è¿›åº¦+æˆåŠŸ+ç¢°æ’+åŠ¨ä½œæˆæœ¬              â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Robot Layer (æœºå™¨äººå±‚)                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚          FishSimple2D (é—¨é¢æ¨¡å¼)                  â”‚      â”‚
â”‚   â”‚  â€¢ ç»„åˆåŠ¨åŠ›å­¦æ¨¡å‹ä¸ç§¯åˆ†å™¨                         â”‚      â”‚
â”‚   â”‚  â€¢ æä¾›ç»Ÿä¸€çš„ step(state, action, dt) æ¥å£       â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Engine Layer (ç‰©ç†å¼•æ“å±‚)                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  åŠ¨åŠ›å­¦    â”‚  â”‚  ç§¯åˆ†å™¨   â”‚  â”‚  åœ°å›¾     â”‚  â”‚  æ´‹æµ     â”‚  â”‚
â”‚   â”‚ Dynamics  â”‚  â”‚Integratorâ”‚  â”‚   Map    â”‚  â”‚ Current  â”‚  â”‚
â”‚   â”‚ â€¢ è´¨ç‚¹æ¨¡å‹ â”‚  â”‚ â€¢ RK4    â”‚  â”‚ â€¢ è¾¹ç•Œ    â”‚  â”‚ â€¢ å‡åŒ€æµ  â”‚  â”‚
â”‚   â”‚ â€¢ æ¨åŠ›     â”‚  â”‚ â€¢ Euler  â”‚  â”‚ â€¢ éšœç¢ç‰©  â”‚  â”‚ â€¢ æ¶¡æ—‹æµ  â”‚  â”‚
â”‚   â”‚ â€¢ é˜»åŠ›     â”‚  â”‚          â”‚  â”‚ â€¢ ç¢°æ’æ£€æµ‹â”‚  â”‚ â€¢ å¤åˆæµ  â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•°æ®æµ

```
é…ç½®æ–‡ä»¶ (JSON) â†’ ç¯å¢ƒåˆå§‹åŒ– â†’ è®­ç»ƒå¾ªç¯ â†’ æ¨¡å‹ä¿å­˜
                                    â†“
                              è¯„ä¼°æµ‹è¯• â†’ æŒ‡æ ‡è®¡ç®— â†’ å¯è§†åŒ–åˆ†æ
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- **Python**: 3.8+
- **æ“ä½œç³»ç»Ÿ**: Linux / macOS / Windows
- **ç¡¬ä»¶**: CPUï¼ˆæ¨èï¼‰æˆ– CUDA GPU

### å®‰è£…æ­¥éª¤

1. **å…‹éš†é¡¹ç›®**

```bash
git clone https://github.com/sleeeeeeeeeeper/RL_fish.git
cd RL_fish
```

2. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**

```bash
# ä½¿ç”¨ conda 
conda create -n RL_fish python=3.12
conda activate RL_fish

```

3. **å®‰è£…ä¾èµ–**

```bash
pip install -r requirements.txt
```

### å¿«é€ŸéªŒè¯

è¿è¡Œä¸€ä¸ªç®€å•çš„è®­ç»ƒå®éªŒï¼š

```bash
# ä½¿ç”¨ PPO ç®—æ³•åœ¨ç®€å•ç¯å¢ƒä¸­è®­ç»ƒ
python task_path/train.py \
    --config task_path/configs/experiments/a1_algorithm/exp_a1_l1_ppo.json 
```

è®­ç»ƒå®Œæˆåè¯„ä¼°æ¨¡å‹ï¼š

```bash
# è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹
python task_path/eval.py \
    --model-path results/exp_a1_l1_ppo_<timestamp>/models/best_model.zip \
    --config task_path/configs/experiments/a1_algorithm/exp_a1_l1_ppo.json \
    --render
```

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
RL_fish/
â”œâ”€â”€ README.md                          # é¡¹ç›®è¯´æ˜æ–‡æ¡£ï¼ˆæœ¬æ–‡ä»¶ï¼‰
â”‚
â”œâ”€â”€ engine/                            # ç‰©ç†å¼•æ“å±‚
â”‚   â”œâ”€â”€ dynamics_2d.py                 # è´¨ç‚¹åŠ¨åŠ›å­¦æ¨¡å‹
â”‚   â”œâ”€â”€ integrator.py                  # æ•°å€¼ç§¯åˆ†å™¨ (Euler/RK4)
â”‚   â”œâ”€â”€ map_2d.py                      # åœ°å›¾ç®¡ç†ï¼ˆè¾¹ç•Œã€éšœç¢ç‰©ï¼‰
â”‚   â”œâ”€â”€ obstacle_2d.py                 # éšœç¢ç‰©å®šä¹‰ï¼ˆé™æ€/åŠ¨æ€ï¼‰
â”‚   â””â”€â”€ ocean_current_2d.py            # æ´‹æµæ¨¡å‹ï¼ˆ5ç§+ç»„åˆï¼‰
â”‚
â”œâ”€â”€ robot/                             # æœºå™¨äººå±‚
â”‚   â””â”€â”€ fish_simple_2d.py              # ä»¿ç”Ÿé±¼æœºå™¨äººæ¨¡å‹
â”‚
â”œâ”€â”€ env/                               # ç¯å¢ƒå±‚
â”‚   â”œâ”€â”€ base_env.py                    # åŸºç¡€ç¯å¢ƒç±»
â”‚   â”œâ”€â”€ path_planning_2d.py            # è·¯å¾„è§„åˆ’ä»»åŠ¡ç¯å¢ƒ
â”‚   â””â”€â”€ renderer_2d.py                 # 2D å¯è§†åŒ–æ¸²æŸ“å™¨
â”‚
â”œâ”€â”€ algorithm/                         # å¼ºåŒ–å­¦ä¹ ç®—æ³•
â”‚   â”œâ”€â”€ ppo.py                         # Proximal Policy Optimization
â”‚   â”œâ”€â”€ sac.py                         # Soft Actor-Critic
â”‚   â””â”€â”€ td3.py                         # Twin Delayed DDPG
â”‚
â”œâ”€â”€ task_path/                         # ä»»åŠ¡ä¸å®éªŒå±‚
â”‚   â”œâ”€â”€ train.py                       # è®­ç»ƒå…¥å£è„šæœ¬
â”‚   â”œâ”€â”€ eval.py                        # è¯„ä¼°å…¥å£è„šæœ¬
â”‚   â”œâ”€â”€ compare.py                     # æ¨¡å‹æ¯”è¾ƒå·¥å…·
â”‚   â”œâ”€â”€ metrics.py                     # æ€§èƒ½æŒ‡æ ‡å®šä¹‰
â”‚   â”œâ”€â”€ utils.py                       # å·¥å…·å‡½æ•°é›†åˆ
â”‚   â”œâ”€â”€ TASK_DOCUMENTATION.md          # ä»»åŠ¡æ–‡æ¡£
â”‚   â”‚
â”‚   â”œâ”€â”€ analysis/                      # æ•°æ®åˆ†æå·¥å…·
â”‚   â”‚   â”œâ”€â”€ data_loader.py             # å®éªŒæ•°æ®åŠ è½½å™¨
â”‚   â”‚   â”œâ”€â”€ metrics_calculator.py      # æŒ‡æ ‡è®¡ç®—
â”‚   â”‚   â”œâ”€â”€ visualization.py           # å›¾è¡¨ç”Ÿæˆ
â”‚   â”‚   â”œâ”€â”€ analyze_a1_algorithms.py   # A1ç»„åˆ†æè„šæœ¬
â”‚   â”‚   â”œâ”€â”€ analyze_a2_environment.py  # A2ç»„åˆ†æè„šæœ¬
â”‚   â”‚   â”œâ”€â”€ analyze_a3_hyperparams.py  # A3ç»„åˆ†æè„šæœ¬
â”‚   â”‚   â”œâ”€â”€ analyze_a4_rewards.py      # A4ç»„åˆ†æè„šæœ¬
â”‚   â”‚   â””â”€â”€ generate_full_report.py    # å®Œæ•´æŠ¥å‘Šç”Ÿæˆ
â”‚   â”‚
â”‚   â”œâ”€â”€ configs/                       # é…ç½®æ–‡ä»¶ç›®å½•
â”‚   â”‚   â””â”€â”€ experiments/
â”‚   â”‚       â”œâ”€â”€ a1_algorithm/          # A1: ç®—æ³•å¯¹æ¯”å®éªŒ
â”‚   â”‚       â”œâ”€â”€ a2_environment/        # A2: ç¯å¢ƒå½±å“å®éªŒ
â”‚   â”‚       â”œâ”€â”€ a3_hyperparameter/     # A3: è¶…å‚æ•°è°ƒä¼˜
â”‚   â”‚       â””â”€â”€ a4_reward/             # A4: å¥–åŠ±å‡½æ•°ä¼˜åŒ–
â”‚   â”‚
â”‚   â””â”€â”€ results/                       # å®éªŒç»“æœå­˜å‚¨
â”‚       â”œâ”€â”€ a1/
â”‚       â”œâ”€â”€ a2/
â”‚       â”œâ”€â”€ a3/
â”‚       â””â”€â”€ a4/
â”‚
â”œâ”€â”€ run_batch_experiments.py           # æ‰¹é‡å®éªŒè¿è¡Œè„šæœ¬
â””â”€â”€ run_batch_eval.py                  # æ‰¹é‡è¯„ä¼°è„šæœ¬
```

---

## âš™ï¸ é…ç½®ç³»ç»Ÿ

### é…ç½®æ–‡ä»¶ç»“æ„

é…ç½®æ–‡ä»¶é‡‡ç”¨åˆ†å±‚ JSON æ ¼å¼ï¼ŒåŒ…å«ä¸‰å¤§éƒ¨åˆ†ï¼š

```json
{
  "env": {
    "task": { /* ä»»åŠ¡å‚æ•° */ },
    "map": { /* åœ°å›¾é…ç½® */ },
    "robot": { /* æœºå™¨äººå‚æ•° */ },
    "sensor": { /* ä¼ æ„Ÿå™¨é…ç½® */ },
    "reward": { /* å¥–åŠ±å‡½æ•° */ }
  },
  "algorithm": {
    "name": "ppo",
    "policy": "MlpPolicy",
    "policy_kwargs": { /* ç­–ç•¥ç½‘ç»œ */ },
    "learning_rate": 3e-4,
    /* ... ç®—æ³•è¶…å‚æ•° ... */
  },
  "training": {
    "total_timesteps": 500000,
    "n_envs": 8,
    "eval_freq": 10000,
    /* ... è®­ç»ƒå‚æ•° ... */
  }
}
```

### å…³é”®é…ç½®é¡¹

#### ä»»åŠ¡é…ç½® (`env.task`)

```json
"task": {
  "dt": 0.05,                    // ä»¿çœŸæ—¶é—´æ­¥é•¿
  "max_episode_steps": 1000,     // æœ€å¤§æ­¥æ•°
  "success_threshold": 0.3       // æˆåŠŸè·ç¦»é˜ˆå€¼
}
```

#### åœ°å›¾é…ç½® (`env.map`)

```json
"map": {
  "bounds": [0, 0, 50, 50],      // è¾¹ç•Œ [x_min, y_min, x_max, y_max]
  "obstacles": {
    "static_circles": [
      {"center": [10, 10], "radius": 2.0}
    ],
    "dynamic_circles": [
      {"center": [20, 20], "radius": 1.5, "movement_type": "linear", ...}
    ]
  },
  "ocean_current": {
    "type": "uniform",           // æ´‹æµç±»å‹
    "params": {"velocity": [0.5, 0.0]}
  }
}
```

#### æœºå™¨äººé…ç½® (`env.robot`)

```json
"robot": {
  "max_thrust": 2.0,             // æœ€å¤§æ¨åŠ›
  "k_drag": 0.05,                // é˜»åŠ›ç³»æ•°
  "integrator": "rk4"            // ç§¯åˆ†å™¨ç±»å‹
}
```

#### å¥–åŠ±å‡½æ•° (`env.reward`)

```json
"reward": {
  "success_reward": 100.0,       // æˆåŠŸå¥–åŠ±
  "collision_penalty": -50.0,    // ç¢°æ’æƒ©ç½š
  "progress_weight": 2.0,        // è¿›åº¦æƒé‡
  "action_cost_weight": 0.01,    // åŠ¨ä½œæˆæœ¬
  "step_penalty_weight": 0.0,    // æ­¥é•¿æƒ©ç½š
  "obstacle_penalty_weight": 0.1,// éšœç¢è·ç¦»æƒ©ç½š
  "obstacle_danger_radius": 3.0  // å±é™©åŠå¾„
}
```

### é…ç½®æ–‡ä»¶ç¤ºä¾‹

æŸ¥çœ‹ `task_path/configs/experiments/` ç›®å½•ä¸‹çš„ç¤ºä¾‹é…ç½®æ–‡ä»¶ã€‚

---

## ğŸ”¬ å®éªŒä½“ç³»

é¡¹ç›®é¢„å®šä¹‰äº†å››å¤§å®éªŒç»„ï¼ˆA1-A4ï¼‰ï¼Œæ¶µç›–ç®—æ³•å¯¹æ¯”ã€ç¯å¢ƒå½±å“ã€è¶…å‚æ•°è°ƒä¼˜å’Œå¥–åŠ±å‡½æ•°ä¼˜åŒ–ã€‚

### A1: ç®—æ³•å¯¹æ¯”å®éªŒ

**ç ”ç©¶é—®é¢˜**: ä¸åŒå¼ºåŒ–å­¦ä¹ ç®—æ³•åœ¨ç›¸åŒç¯å¢ƒä¸‹çš„æ€§èƒ½å·®å¼‚ï¼Ÿ

| å®éªŒ ID       | ç®—æ³• | éš¾åº¦çº§åˆ« | é…ç½®æ–‡ä»¶                            |
| ------------- | ---- | -------- | ----------------------------------- |
| exp_a1_l1_ppo | PPO  | L1-Easy  | `a1_algorithm/exp_a1_l1_ppo.json` |
| exp_a1_l1_sac | SAC  | L1-Easy  | `a1_algorithm/exp_a1_l1_sac.json` |
| exp_a1_l1_td3 | TD3  | L1-Easy  | `a1_algorithm/exp_a1_l1_td3.json` |
| ...           | ...  | L2-L5    | ...                                 |

**è¿è¡Œæ–¹å¼**:

```bash
# å•ä¸ªå®éªŒ
python task_path/train.py --config task_path/configs/experiments/a1_algorithm/exp_a1_l1_ppo.json

# æ‰¹é‡è¿è¡Œ A1 ç»„æ‰€æœ‰å®éªŒ
python run_batch_experiments.py --config-dir task_path/configs/experiments/a1_algorithm --concurrency 3
```

**åˆ†æ**:

```bash
python task_path/analysis/analyze_a1_algorithms.py --results-dir task_path/results/a1
```

### A2: ç¯å¢ƒå½±å“å®éªŒ

**ç ”ç©¶é—®é¢˜**: ç¯å¢ƒå‚æ•°ï¼ˆéšœç¢ç‰©å¯†åº¦ã€æ´‹æµå¼ºåº¦ã€ç›®æ ‡è·ç¦»ï¼‰å¦‚ä½•å½±å“ç®—æ³•æ€§èƒ½ï¼Ÿ

#### A2.1 éšœç¢ç‰©å¯†åº¦

- `exp_a2_obs_sp` - ç¨€ç–éšœç¢ç‰© (5-8ä¸ª)
- `exp_a2_obs_md` - ä¸­ç­‰å¯†åº¦ (12-15ä¸ª)
- `exp_a2_obs_dn` - å¯†é›†éšœç¢ç‰© (20-25ä¸ª)
- `exp_a2_obs_mz` - è¿·å®«ç»“æ„ (30-40ä¸ª)

#### A2.2 æ´‹æµç±»å‹

- `exp_a2_current_nc` - æ— æ´‹æµ
- `exp_a2_current_uc` - å‡åŒ€æ´‹æµ
- `exp_a2_current_vc` - æ¶¡æ—‹æ´‹æµ

#### A2.3 ç›®æ ‡è·ç¦»

- `exp_a2_dist_sd` - çŸ­è·ç¦» (15m)
- `exp_a2_dist_md` - ä¸­è·ç¦» (30m)
- `exp_a2_dist_ld` - é•¿è·ç¦» (50m)

### A3: è¶…å‚æ•°è°ƒä¼˜å®éªŒ

**ç ”ç©¶é—®é¢˜**: å­¦ä¹ ç‡ã€æ‰¹é‡å¤§å°ã€ç¼“å†²åŒºå¤§å°ç­‰è¶…å‚æ•°çš„æ•æ„Ÿæ€§ï¼Ÿ

é’ˆå¯¹æ¯ä¸ªç®—æ³•ï¼ˆPPO/SAC/TD3ï¼‰åˆ†åˆ«è°ƒä¼˜ï¼š

- **å­¦ä¹ ç‡**: 1e-5 ~ 1e-3
- **æ‰¹é‡å¤§å°**: 32, 64, 128, 256
- **å…¶ä»–**: epochæ•°ã€clipèŒƒå›´ã€æŠ˜æ‰£å› å­ç­‰

### A4: å¥–åŠ±å‡½æ•°ä¼˜åŒ–å®éªŒ

**ç ”ç©¶é—®é¢˜**: ä¸åŒå¥–åŠ±å‡½æ•°è®¾è®¡å¯¹è®­ç»ƒæ•ˆæœçš„å½±å“ï¼Ÿ

- `exp_a4_reward_baseline` - åŸºå‡†å¥–åŠ±å‡½æ•°
- `exp_a4_reward_dense` - å¯†é›†å¥–åŠ±ï¼ˆæ›´é¢‘ç¹çš„åé¦ˆï¼‰
- `exp_a4_reward_sparse` - ç¨€ç–å¥–åŠ±ï¼ˆä»…ç»ˆæ€å¥–åŠ±ï¼‰
- `exp_a4_reward_energy` - èƒ½é‡çº¦æŸï¼ˆæƒ©ç½šå¤§åŠ¨ä½œï¼‰
- `exp_a4_reward_nostep` - æ— æ­¥é•¿æƒ©ç½š

---

## ğŸ“– ä½¿ç”¨æŒ‡å—

### è®­ç»ƒæ¨¡å‹

#### åŸºæœ¬ç”¨æ³•

```bash
python task_path/train.py \
    --config <path_to_config.json> \
    --algo <ppo|sac|td3>
```

#### å¸¸ç”¨é€‰é¡¹

```bash
# ä½¿ç”¨è‡ªå®šä¹‰å®ç°çš„ç®—æ³•
python task_path/train.py --config config.json --algo ppo --use-custom

# æŒ‡å®šè¾“å‡ºç›®å½•
python task_path/train.py --config config.json --output-dir my_results

# è®¾ç½®éšæœºç§å­
python task_path/train.py --config config.json --seed 42

# å¯ç”¨è¯¦ç»†æ—¥å¿—
python task_path/train.py --config config.json --verbose
```

### è¯„ä¼°æ¨¡å‹

#### åŸºæœ¬è¯„ä¼°

```bash
python task_path/eval.py \
    --model-path results/exp_xxx/models/best_model.zip \
    --config task_path/configs/experiments/xxx.json \
    --n-episodes 100
```

#### ç”Ÿæˆå¯è§†åŒ–

```bash
# æ¸²æŸ“è½¨è¿¹åŠ¨ç”»
python task_path/eval.py \
    --model-path results/exp_xxx/models/best_model.zip \
    --config task_path/configs/experiments/xxx.json \
    --render \
```

### æ‰¹é‡å®éªŒ

#### è¿è¡Œæ•´ä¸ªå®éªŒç»„

```bash
# è¿è¡Œ A1 ç»„æ‰€æœ‰å®éªŒï¼Œ3ä¸ªå¹¶å‘
python run_batch_experiments.py \
    --config-dir task_path/configs/experiments/a1_algorithm \
    --concurrency 3 \
    --output-dir task_path/results/a1
```

#### æ‰¹é‡è¯„ä¼°

```bash
python run_batch_eval.py \
    --results-dir task_path/results/a1 \
    --n-episodes 100
```

---

## ğŸ“Š åˆ†æä¸å¯è§†åŒ–

### è‡ªåŠ¨åˆ†ææŠ¥å‘Š

æ¯ä¸ªå®éªŒç»„éƒ½æœ‰å¯¹åº”çš„åˆ†æè„šæœ¬ï¼š

```bash
# A1: ç®—æ³•å¯¹æ¯”åˆ†æ
python task_path/analysis/analyze_a1_algorithms.py --results-dir task_path/results/a1

# A2: ç¯å¢ƒå½±å“åˆ†æ
python task_path/analysis/analyze_a2_environment.py --results-dir task_path/results/a2

# A3: è¶…å‚æ•°åˆ†æ
python task_path/analysis/analyze_a3_hyperparams.py --results-dir task_path/results/a3

# A4: å¥–åŠ±å‡½æ•°åˆ†æ
python task_path/analysis/analyze_a4_rewards.py --results-dir task_path/results/a4
```

### å®Œæ•´å®éªŒæŠ¥å‘Š

ç”ŸæˆåŒ…å«æ‰€æœ‰å®éªŒç»„çš„ç»¼åˆæŠ¥å‘Šï¼š

```bash
python task_path/analysis/generate_full_report.py \
    --results-dir task_path/results \
    --output-dir reports
```

### å¯è§†åŒ–å›¾è¡¨ç±»å‹

- **å­¦ä¹ æ›²çº¿**: è®­ç»ƒå›æŠ¥éšæ—¶é—´çš„å˜åŒ–
- **æˆåŠŸç‡å¯¹æ¯”**: ä¸åŒé…ç½®çš„æˆåŠŸç‡æŸ±çŠ¶å›¾
- **æ€§èƒ½é›·è¾¾å›¾**: å¤šç»´åº¦æ€§èƒ½å¯¹æ¯”
- **è½¨è¿¹å¯è§†åŒ–**: æœºå™¨äººè¿åŠ¨è½¨è¿¹åŠ¨ç”»
- **æ´‹æµåœº**: æ´‹æµçŸ¢é‡åœºå¯è§†åŒ–

---

### æ€§èƒ½æŒ‡æ ‡

`PathPlanningMetrics` ç±»æä¾›ä»¥ä¸‹æŒ‡æ ‡ï¼š

- **æˆåŠŸç‡** (`success_rate`): æˆåŠŸåˆ°è¾¾ç›®æ ‡çš„æ¯”ä¾‹
- **ç¢°æ’ç‡** (`collision_rate`): å‘ç”Ÿç¢°æ’çš„æ¯”ä¾‹
- **å¹³å‡å›æŠ¥** (`mean_reward`): å¹³å‡ç´¯ç§¯å¥–åŠ±
- **å¹³å‡æ­¥æ•°** (`mean_episode_length`): æˆåŠŸè½¨è¿¹çš„å¹³å‡æ­¥æ•°
- **è·¯å¾„é•¿åº¦** (`mean_path_length`): å®é™…è¡Œé©¶è·ç¦»
- **è·¯å¾„å¹³æ»‘åº¦** (`mean_path_smoothness`): è½¨è¿¹æ›²ç‡å˜åŒ–
- **èƒ½é‡æ¶ˆè€—** (`mean_energy_consumption`): ç´¯ç§¯åŠ¨ä½œèƒ½é‡
- **æœ€å°éšœç¢è·ç¦»** (`mean_min_obstacle_distance`): ä¸éšœç¢ç‰©çš„æœ€å°è·ç¦»

---

## ğŸ› ï¸ å¼€å‘æŒ‡å—

### æ·»åŠ æ–°ç®—æ³•

1. åœ¨ `algorithm/` ä¸‹åˆ›å»ºæ–°æ–‡ä»¶
2. ç»§æ‰¿ `OnPolicyAlgorithm` æˆ– `OffPolicyAlgorithm`
3. å®ç° `_setup_model()` å’Œ `train()` æ–¹æ³•
4. åœ¨ `task_path/utils.py` çš„ `create_model()` ä¸­æ³¨å†Œ

### æ·»åŠ æ–°ç¯å¢ƒ

1. åœ¨ `env/` ä¸‹åˆ›å»ºæ–°ç¯å¢ƒç±»
2. ç»§æ‰¿ `FishEnvBase` æˆ–ç›´æ¥ç»§æ‰¿ `gymnasium.Env`
3. å®ç°å¿…è¦çš„æ–¹æ³•ï¼š`reset()`, `step()`, `render()`
4. åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šæ–°ç¯å¢ƒ

---
## TODO

1. æ‹“å±•è‡³3dç¯å¢ƒ
2. æ”¯æŒçœŸå®åœ°å½¢æ•°æ®å¯¼å…¥
3. æ›´çœŸå®å¤æ‚çš„æœºå™¨é±¼æ¨¡å‹
4. æ›´çœŸå®çš„ç‰©ç†æ•ˆæœ
5. æ‹“å±•ä»»åŠ¡ç±»å‹ï¼ˆå¦‚ç›®æ ‡è·Ÿè¸ªã€å§¿æ€æ§åˆ¶ä»¥åŠå¤šé±¼ååŒç­‰ï¼‰

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶
